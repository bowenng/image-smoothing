{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from core.data.data import Dataset\n",
    "from core.loss.loss import TotalLoss\n",
    "from core.network.smoothingnetwork import SmoothingNet\n",
    "from core.data.makeedge import make_edge_files\n",
    "from torch.optim import Adam\n",
    "from torch.utils import data\n",
    "from torch import autograd\n",
    "from torch import nn\n",
    "import torch\n",
    "from core.loss.dataloss import DataLoss\n",
    "from core.loss.smoothnessloss import SmoothnessLoss\n",
    "from core.loss.edgepreservingloss import EdgePreservingLoss\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "#make_edge_files(\"data/eval\", \"data/eval_edges\", os.getcwd(), high=255, low=150)\n",
    "\n",
    "def show_generated_images(dataset, net, device,show_n=5):\n",
    "    with torch.no_grad():\n",
    "        image_idx = np.random.choice(len(dataset), show_n)\n",
    "        image_idx\n",
    "        images = []\n",
    "        for idx in image_idx:\n",
    "            images.append(dataset[idx][0])\n",
    "\n",
    "        def show(img,ax):\n",
    "            npimg = img.cpu().numpy()\n",
    "            ax.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "        \n",
    "        \n",
    "        fig, axs = plt.subplots(2, figsize = (20,10))\n",
    "        images = torch.stack(images).to(device)\n",
    "        output_images = net(images).clamp(0.0,1.0)\n",
    "        \n",
    "        show(torchvision.utils.make_grid(images, padding=50), axs[0])\n",
    "        show(torchvision.utils.make_grid(output_images, padding=50), axs[1])\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "def train(net, epochs, batch_size, optimizer, dataset, window_size=5,device='cuda'):\n",
    "    dataloader = data.DataLoader(dataset, batch_size=batch_size)\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    \n",
    "    # criteria = TotalLoss().to(device)\n",
    "    data_loss = DataLoss()\n",
    "    smoothness_loss = SmoothnessLoss(window_size=window_size)\n",
    "    edge_preserving_loss = EdgePreservingLoss()\n",
    "    w_data = 1.0\n",
    "    w_smooth = 1.0\n",
    "    w_edge_preserving = 0.1\n",
    "    n = 0\n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch: {}\".format(e+1))\n",
    "        for i, (images, binary_mask) in enumerate(dataloader):\n",
    "            n += 1\n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            binary_mask = binary_mask.to(device)\n",
    "            \n",
    "            smooth_images_residual = net(images)\n",
    "            #print(torch.mean(smooth_images_residual))\n",
    "            #print(torch.max(smooth_images_residual))\n",
    "            #print(torch.max(images))\n",
    "            smooth_images = smooth_images_residual# + images\n",
    "\n",
    "            #with autograd.detect_anomaly():\n",
    "            #ts = time.time()\n",
    "            D = w_data * data_loss(images, smooth_images)  \n",
    "            S = w_smooth * smoothness_loss(images, smooth_images)  \n",
    "            E = w_edge_preserving * edge_preserving_loss(binary_mask, images, smooth_images)\n",
    "            loss = D + S + E\n",
    "            #te = time.time()\n",
    "            #print(\"{}: {}\".format(\"Total Loss\", (te - ts) * 1000))\n",
    "\n",
    "            #ts = time.time()\n",
    "            loss.backward()\n",
    "            #te = time.time()\n",
    "            #print(\"{}: {}\".format(\"Backprop\", (te - ts) * 1000))\n",
    "\n",
    "            #ts = time.time()\n",
    "            optimizer.step()\n",
    "            #te = time.time()\n",
    "            #print(\"{}: {}\".format(\"Step\", (te - ts) * 1000))\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\tN: {}\".format(n))\n",
    "                show_generated_images(dataset=dataset, net=net, device=device)\n",
    "                print(\"\\tD: {:.5f}\".format(D.item()), end=' ')\n",
    "                print(\"\\tS: {:.5f}\".format(S.item()), end=' ')\n",
    "                print(\"\\tE: {:.5f}\".format(E.item()), end=' ')\n",
    "                print(\"\\tTotal: {}\".format(loss))\n",
    "                torch.save({'state_dict':net.state_dict(),\n",
    "                                'epoch':e}, ('model.pth'))\n",
    "                \n",
    "                \n",
    "net = SmoothingNet()\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 1\n",
    "data_dir = \"data\"\n",
    "dataset = Dataset(os.path.join(data_dir, \"train2014\"), os.path.join(data_dir, \"edges\"), edge_prefix='')\n",
    "\n",
    "optimizer = Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "#net.apply(init_weights)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "train(net, epochs, batch_size, optimizer, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
